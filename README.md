
<!-- Title -->
<h1 align="center">ğŸš€ Fino1</h1>

<p align="center">
  <a href="https://your-paper-link.com">ğŸ“„ Our Paper</a> |
  <a href="https://your-model-link.com">ğŸ¤– Our Model</a>
</p>

---

## ğŸ“ˆ Overview

### ğŸ“‚ Datasets Used
Here, we used 3 evaluation datasets to assess our Fino1 model

| Dataset | Description |
|---------|-------------|
| **[FinQA](https://your-dataset1-link.com)** | descriptions |
| **[DocMath](https://your-dataset2-link.com)** | descriptions |
| **[XBRL-Math](https://your-dataset3-link.com)** | descriptions |

### ğŸ† Models Evaluated
We used 16 state-of-the-art large language models (LLMs) to compare with our Fino1 model

| Model | Description |
|-------|------------|
| **[GPT-4o](https://your-model1-link.com)** | descriptions |
| **[GPT-o1](https://your-model2-link.com)** | descriptions |
| **[GPT-o3-mini](https://your-model3-link.com)** | descriptions |
| **[DeepSeek-V3](https://your-model4-link.com)** | descriptions |
| **[DeepSeek-R1](https://your-model5-link.com)** | descriptions |


### Reasoning path building
Here is the content of the building reasoning path

### How to train Fino1
For the training part, we were inspired by [Huatuo-GPT o1](https://your-model5-link.com)

---

## ğŸ¯ Key Highlights
âœ… **Superior performance across 10 benchmarks**  
âœ… **Achieves strong generalization with only 1% data**  
âœ… **Significant improvement over larger datasets**  

---

## ğŸ› ï¸ Updates

- **[2024/02/10]** ğŸ‰ We've added LIMO's performance on the recently completed 
  [AIME 2025 Part 1 evaluation](https://your-link.com), where it achieved a solid score of **44.5**, 
  demonstrating competitive performance using only **817 training samples** compared to other models 
  trained on much larger datasets (**800k samples**).

- **[2024/02/10]** ğŸ‰ [**Third-party evaluations**](https://your-link.com) highlight LIMO's strong generalization capabilities.

- **[2025/02/08]** ğŸ“¢ The LIMO dataset has received positive recognition from the 
  [community](https://your-link.com). According to third-party evaluations, the dataset achieved a 
  **10-percentage point improvement** on AIME24 and GPQA be
